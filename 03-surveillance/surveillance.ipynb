{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2247f8-5922-439a-9265-1ef154f8f530",
   "metadata": {},
   "source": [
    "# Surveillance\n",
    "\n",
    "Esse `Jupyter Notebook` possui a finalidade de mostrar o passo a passo de funcionamento do script.\n",
    "\n",
    "É muito provável que a versão `.py` tenha um melhor desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bf942-1163-4a16-9faa-d76bb06a1fab",
   "metadata": {},
   "source": [
    "## 1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fe0ffa-2c4c-4311-89cd-eeb71cfb1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas necessárias\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ed893-de73-4f39-a03e-8a05c9db6fd7",
   "metadata": {},
   "source": [
    "## 2. Modelo treinado\n",
    "\n",
    "Recorde o endereço (_path_) onde o modelo treinado está salvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22715954-69ba-4412-b7e1-54471b74b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do arquivo do modelo\n",
    "model_path = 'C:/Users/ander/Documents/jupyter_notebooks/ppe_surveillance/02-training/runs/detect/train2/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe44726-ff1f-4c0c-8610-7eed8344cf8a",
   "metadata": {},
   "source": [
    "## 3. Supervisão\n",
    "\n",
    "Uso da câmera do laptop para verificar se a pessoa está usando o EPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528b5ed3-db63-4b34-afd3-1091d1f0c5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 116 helmets, 5 glasses EPIs, 179 ear protectors, 692.2ms\n",
      "Speed: 2.0ms preprocess, 692.2ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 218 helmets, 19 glasses EPIs, 63 ear protectors, 635.1ms\n",
      "Speed: 2.0ms preprocess, 635.1ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 277 helmets, 17 glasses EPIs, 2 ear protectors, 4 glovess, 603.2ms\n",
      "Speed: 1.1ms preprocess, 603.2ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 228 helmets, 12 glasses EPIs, 49 ear protectors, 11 glovess, 608.5ms\n",
      "Speed: 2.1ms preprocess, 608.5ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 265 helmets, 13 glasses EPIs, 17 ear protectors, 5 glovess, 601.7ms\n",
      "Speed: 2.4ms preprocess, 601.7ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 166 helmets, 64 glasses EPIs, 68 ear protectors, 2 glovess, 592.6ms\n",
      "Speed: 2.1ms preprocess, 592.6ms inference, 13.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 189 helmets, 16 glasses EPIs, 94 ear protectors, 1 gloves, 597.3ms\n",
      "Speed: 1.0ms preprocess, 597.3ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 265 helmets, 5 glasses EPIs, 7 ear protectors, 23 glovess, 613.6ms\n",
      "Speed: 2.0ms preprocess, 613.6ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 136 helmets, 155 glasses EPIs, 9 ear protectors, 603.9ms\n",
      "Speed: 2.5ms preprocess, 603.9ms inference, 22.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 30 helmets, 270 ear protectors, 598.6ms\n",
      "Speed: 2.1ms preprocess, 598.6ms inference, 21.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 276 helmets, 2 glasses EPIs, 17 ear protectors, 5 glovess, 597.3ms\n",
      "Speed: 2.1ms preprocess, 597.3ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 291 helmets, 8 glasses EPIs, 1 gloves, 640.1ms\n",
      "Speed: 2.1ms preprocess, 640.1ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 helmets, 71 glasses EPIs, 215 ear protectors, 656.0ms\n",
      "Speed: 2.4ms preprocess, 656.0ms inference, 25.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 102 helmets, 64 glasses EPIs, 134 ear protectors, 672.3ms\n",
      "Speed: 2.0ms preprocess, 672.3ms inference, 12.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 31 helmets, 55 glasses EPIs, 214 ear protectors, 797.6ms\n",
      "Speed: 2.0ms preprocess, 797.6ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 280 helmets, 2 glasses EPIs, 16 ear protectors, 2 glovess, 649.8ms\n",
      "Speed: 2.4ms preprocess, 649.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 290 helmets, 2 glasses EPIs, 1 ear protector, 7 glovess, 635.4ms\n",
      "Speed: 2.4ms preprocess, 635.4ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 253 helmets, 20 glasses EPIs, 19 ear protectors, 8 glovess, 719.7ms\n",
      "Speed: 3.0ms preprocess, 719.7ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 240 helmets, 47 glasses EPIs, 9 ear protectors, 4 glovess, 691.1ms\n",
      "Speed: 2.1ms preprocess, 691.1ms inference, 9.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 182 helmets, 17 glasses EPIs, 101 ear protectors, 747.2ms\n",
      "Speed: 3.7ms preprocess, 747.2ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Verificar se o arquivo existe\n",
    "if not os.path.isfile(model_path):\n",
    "    print(f\"Erro: O arquivo '{model_path}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar o modelo treinado\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Inicializar a captura de vídeo\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erro ao abrir a câmera\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Erro ao capturar frame\")\n",
    "            break\n",
    "\n",
    "        # Realizar a detecção\n",
    "        results = model(frame)\n",
    "\n",
    "        # Renderizar resultados na imagem\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Mostrar a imagem com caixas\n",
    "        cv2.imshow('YOLOv8 EPI Detection', annotated_frame)\n",
    "\n",
    "        # Sair do loop ao pressionar a tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Liberar a captura e fechar janelas\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
